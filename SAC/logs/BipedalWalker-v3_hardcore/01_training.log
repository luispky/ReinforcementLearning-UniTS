SAC Agent Configuration:
hidden_units: [256, 256]
conv_layers: None
log_std_interval: [-20, 2]
gamma: 0.99
load_best: False
replay_buffer_size: 200000
batch_size: 256
init_temperature: 0.2
actor_lr: 0.0003
critic_lr: 0.0003
temperature_lr: 0.0003
actor_update_freq: 1
critic_target_update_freq: 1
tau: 0.005

Train Configuration:
gradient_steps: 1
max_episodes: 1000
warmup_steps: 15000
print_interval: 20
checkpoint_interval: 50
test_episodes: 25
save_replay_buffer: False

Environment Seed: None

Starting SAC Training

No pre-trained model found, training from scratch.

Episode 20 - Reward: -101.29 - Alpha: 0.20000 - Steps: 9222
Episode 40 - Reward: -115.10 - Alpha: 0.16421 - Steps: 15707
Episode 60 - Reward: -102.74 - Alpha: 0.08368 - Steps: 18581
Episode 80 - Reward: -105.73 - Alpha: 0.06541 - Steps: 19715
Episode 100 - Reward: -106.71 - Alpha: 0.05092 - Steps: 20896
Episode 120 - Reward: -103.04 - Alpha: 0.03726 - Steps: 22379
Episode 140 - Reward: -129.24 - Alpha: 0.01282 - Steps: 27485
Episode 160 - Reward: -88.47 - Alpha: 0.00330 - Steps: 34105
Episode 180 - Reward: -97.71 - Alpha: 0.00032 - Steps: 55438
Episode 200 - Reward: -162.82 - Alpha: 0.00025 - Steps: 79952
Episode 220 - Reward: -42.64 - Alpha: 0.00011 - Steps: 100064
Episode 240 - Reward: -125.64 - Alpha: 0.00078 - Steps: 112528
Episode 260 - Reward: -107.99 - Alpha: 0.00120 - Steps: 113746
Episode 280 - Reward: -106.37 - Alpha: 0.00158 - Steps: 115052
Episode 300 - Reward: -106.97 - Alpha: 0.00149 - Steps: 116410
Episode 320 - Reward: -103.49 - Alpha: 0.00163 - Steps: 117684
Episode 340 - Reward: -102.30 - Alpha: 0.00224 - Steps: 118890
Episode 360 - Reward: -101.78 - Alpha: 0.00271 - Steps: 120073
Episode 380 - Reward: -180.80 - Alpha: 0.00042 - Steps: 131939
Episode 400 - Reward: -101.00 - Alpha: 0.00026 - Steps: 157657
Episode 420 - Reward: -72.79 - Alpha: 0.00013 - Steps: 170691
Episode 440 - Reward: -90.19 - Alpha: 0.00035 - Steps: 192128
Episode 460 - Reward: -84.99 - Alpha: 0.00031 - Steps: 202917
Episode 480 - Reward: -133.78 - Alpha: 0.00041 - Steps: 222417
Episode 500 - Reward: -104.52 - Alpha: 0.00028 - Steps: 239938
Episode 520 - Reward: -98.09 - Alpha: 0.00038 - Steps: 262121
Episode 540 - Reward: -84.99 - Alpha: 0.00046 - Steps: 277063
Episode 560 - Reward: -51.83 - Alpha: 0.00028 - Steps: 294897
Episode 580 - Reward: -106.65 - Alpha: 0.00033 - Steps: 306276
Episode 600 - Reward: -98.39 - Alpha: 0.00043 - Steps: 326530
Episode 620 - Reward: -106.10 - Alpha: 0.00047 - Steps: 339672
Episode 640 - Reward: -92.14 - Alpha: 0.00089 - Steps: 349947
Episode 660 - Reward: -89.49 - Alpha: 0.00107 - Steps: 367366
Episode 680 - Reward: -126.94 - Alpha: 0.00048 - Steps: 380524
Episode 700 - Reward: -41.93 - Alpha: 0.00081 - Steps: 399081
Episode 720 - Reward: -9.74 - Alpha: 0.00128 - Steps: 417419
Episode 740 - Reward: -75.12 - Alpha: 0.00079 - Steps: 433589
Episode 760 - Reward: -108.12 - Alpha: 0.00057 - Steps: 449094
Episode 780 - Reward: -81.77 - Alpha: 0.00067 - Steps: 465594
Episode 800 - Reward: -73.23 - Alpha: 0.00102 - Steps: 490815
Episode 820 - Reward: -93.81 - Alpha: 0.00100 - Steps: 503346
Episode 840 - Reward: -52.79 - Alpha: 0.00078 - Steps: 519997
Episode 860 - Reward: -108.97 - Alpha: 0.00060 - Steps: 530421
Episode 880 - Reward: -33.39 - Alpha: 0.00061 - Steps: 545834
Episode 900 - Reward: -66.62 - Alpha: 0.00110 - Steps: 560441
Episode 920 - Reward: -60.09 - Alpha: 0.00130 - Steps: 575122
Episode 940 - Reward: -15.25 - Alpha: 0.00099 - Steps: 594635
Episode 960 - Reward: -137.41 - Alpha: 0.00094 - Steps: 614084
Episode 980 - Reward: -63.89 - Alpha: 0.00069 - Steps: 636129
Episode 1000 - Reward: -86.08 - Alpha: 0.00067 - Steps: 657352
Training time: 3h 49m 18s
Reward over 25 episodes: -60.64 Â± 20.33
Total Reward of Policy Evaluation: -91.81
Loaded model with reward: 24.17 and alpha: 0.00066
Loaded best agent checkpoint.
Total Reward of Policy Evaluation: -45.65
