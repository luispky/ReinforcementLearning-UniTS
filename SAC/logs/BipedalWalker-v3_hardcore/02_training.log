SAC Agent Configuration:
hidden_units: [256, 256]
conv_layers: None
log_std_interval: [-20, 2]
gamma: 0.99
load_best: False
replay_buffer_size: 200000
batch_size: 256
init_temperature: 0.2
actor_lr: 0.0003
critic_lr: 0.0003
temperature_lr: 0.0003
actor_update_freq: 1
critic_target_update_freq: 1
tau: 0.005

Train Configuration:
gradient_steps: 1
max_episodes: 1000
warmup_steps: 15000
print_interval: 20
checkpoint_interval: 50
test_episodes: 25
save_replay_buffer: False

Environment Seed: 42

Starting SAC Training

No pre-trained model found, training from scratch.

Episode 20 - Reward: -100.26 - Alpha: 0.20000 - Steps: 4898
Episode 40 - Reward: -119.02 - Alpha: 0.20000 - Steps: 11772
Episode 60 - Reward: -192.71 - Alpha: 0.08213 - Steps: 18630
Episode 80 - Reward: -190.22 - Alpha: 0.02000 - Steps: 25382
Episode 100 - Reward: -132.72 - Alpha: 0.00178 - Steps: 37196
Episode 120 - Reward: -135.10 - Alpha: 0.00081 - Steps: 41946
Episode 140 - Reward: -126.33 - Alpha: 0.00028 - Steps: 57738
Episode 160 - Reward: -114.37 - Alpha: 0.00021 - Steps: 68088
Episode 180 - Reward: -111.71 - Alpha: 0.00026 - Steps: 90658
Episode 200 - Reward: -121.85 - Alpha: 0.00059 - Steps: 108838
Episode 220 - Reward: -115.89 - Alpha: 0.00047 - Steps: 111936
Episode 240 - Reward: -111.28 - Alpha: 0.00042 - Steps: 114605
Episode 260 - Reward: -99.01 - Alpha: 0.00035 - Steps: 125584
Episode 280 - Reward: -66.53 - Alpha: 0.00019 - Steps: 153370
Episode 300 - Reward: -80.23 - Alpha: 0.00012 - Steps: 176306
Episode 320 - Reward: -61.24 - Alpha: 0.00012 - Steps: 195979
Episode 340 - Reward: -88.67 - Alpha: 0.00024 - Steps: 220121
Episode 360 - Reward: -111.70 - Alpha: 0.00018 - Steps: 250970
Episode 380 - Reward: -116.72 - Alpha: 0.00017 - Steps: 271895
Episode 400 - Reward: -99.71 - Alpha: 0.00013 - Steps: 290241
Episode 420 - Reward: -98.29 - Alpha: 0.00025 - Steps: 292375
Episode 440 - Reward: -98.71 - Alpha: 0.00079 - Steps: 294713
Episode 460 - Reward: -96.99 - Alpha: 0.00063 - Steps: 302585
Episode 480 - Reward: -79.22 - Alpha: 0.00015 - Steps: 318856
Episode 500 - Reward: -114.32 - Alpha: 0.00028 - Steps: 344807
Episode 520 - Reward: -103.27 - Alpha: 0.00024 - Steps: 351126
Episode 540 - Reward: -92.88 - Alpha: 0.00032 - Steps: 365342
Episode 560 - Reward: -94.45 - Alpha: 0.00032 - Steps: 372191
Episode 580 - Reward: -97.75 - Alpha: 0.00026 - Steps: 374801
Episode 600 - Reward: -129.69 - Alpha: 0.00043 - Steps: 388341
Episode 620 - Reward: -104.14 - Alpha: 0.00031 - Steps: 411387
Episode 640 - Reward: -75.66 - Alpha: 0.00045 - Steps: 431819
Episode 660 - Reward: -143.42 - Alpha: 0.00044 - Steps: 452105
Episode 680 - Reward: -59.98 - Alpha: 0.00074 - Steps: 476917
Episode 700 - Reward: -89.18 - Alpha: 0.00036 - Steps: 488209
Episode 720 - Reward: -96.03 - Alpha: 0.00031 - Steps: 507070
Episode 740 - Reward: -90.94 - Alpha: 0.00034 - Steps: 521147
Episode 760 - Reward: -104.13 - Alpha: 0.00032 - Steps: 533130
Episode 780 - Reward: -94.03 - Alpha: 0.00042 - Steps: 548351
Episode 800 - Reward: -133.39 - Alpha: 0.00054 - Steps: 564394
Episode 820 - Reward: -65.28 - Alpha: 0.00048 - Steps: 581514
Episode 840 - Reward: -138.29 - Alpha: 0.00342 - Steps: 610148
Episode 860 - Reward: -109.37 - Alpha: 0.00141 - Steps: 625141
Episode 880 - Reward: -117.11 - Alpha: 0.00080 - Steps: 635997
Episode 900 - Reward: -126.00 - Alpha: 0.00072 - Steps: 653258
Episode 920 - Reward: -96.97 - Alpha: 0.00077 - Steps: 669741
Episode 940 - Reward: -84.41 - Alpha: 0.00096 - Steps: 685977
Episode 960 - Reward: -134.42 - Alpha: 0.00086 - Steps: 700534
Episode 980 - Reward: -38.51 - Alpha: 0.00119 - Steps: 718801
Episode 1000 - Reward: -97.55 - Alpha: 0.00350 - Steps: 736143
Training time: 4h 1m 35s
Reward over 25 episodes: -104.45 Â± 4.20
Total Reward of Policy Evaluation: -104.61
Loaded model with reward: -29.03 and alpha: 0.00028
Loaded best agent checkpoint.
Total Reward of Policy Evaluation: -31.47
